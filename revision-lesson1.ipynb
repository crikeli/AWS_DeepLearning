{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Below, is code for creating the VGG16 model from scratch using Keras as well as the training weights for the Vgg16 model made available by the researchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "# importing image allows to get the function ImageDataGenerator\n",
    "# it generates batches of tensor image data that augments data in realtime.\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next step is to retrieve all the classes that the VGG16 model contains so that the classes can then be displayed properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n",
      "1000\n",
      "344\n",
      "[u'n02398521', u'hippopotamus']\n",
      "(u'344', [u'n02398521', u'hippopotamus'])\n",
      "0\n",
      "[u'n01440764', u'tench']\n",
      "tench\n"
     ]
    }
   ],
   "source": [
    "# This is the path of the file which contains the class names in dictionary format.\n",
    "FILEPATH = 'http://www.platform.ai/models/'; CLASS_FILE= 'imagenet_class_index.json'\n",
    "\n",
    "fpath = get_file(CLASS_FILE, FILEPATH+CLASS_FILE, cache_subdir='models')\n",
    "\n",
    "# The file is opened and the json data is loaded as class_dict\n",
    "with open(fpath) as f:class_dict = json.load(f)\n",
    "    \n",
    "print(type(class_dict))\n",
    "\n",
    "print(len(class_dict))\n",
    "\n",
    "print class_dict.keys()[0]\n",
    "print class_dict.values()[0]\n",
    "# Basically, the item is a tuple that has an index number that maps to\n",
    "# an array that holds the id of the item in the 0th position & the actual class in the first position\n",
    "print class_dict.items()[0]\n",
    "\n",
    "print str(0)\n",
    "sth = class_dict[str(0)] \n",
    "print sth\n",
    "print sth[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'tench', u'goldfish', u'great_white_shark', u'tiger_shark', u'hammerhead']\n"
     ]
    }
   ],
   "source": [
    "# As shown above, the class_dictionary is accessed to retrieve all the classes in the form of an array\n",
    "classes = [class_dict[str(i)][1] for i in range(len(class_dict))]\n",
    "\n",
    "print classes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a pretty important step.\n",
    "\n",
    "### Below, is how the building blocks of the model are created. By building blocks, I mean the types of layers that the model consists. In this case, the layers are convolutional layers and fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvolutionalLayer(layers, model, filters):\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(2,2), strides=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FullyConnectedLayer(model):\n",
    "    model.add(Dense (4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next step is a little nuanced, and I am still not completely sure on why this is necessary, but it has something to do with how the RGB channels  are used in training the VGG model. \n",
    "\n",
    "- When the model was trained by the original researchers, their deep learning library accepted color channels in the form of BGR.\n",
    "- Python accepts color channels in the form of RGB, so that needs to be accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The mean of each BGR channel is provided by researchers.\n",
    "# A reshaped 3X1 array is returned.\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean\n",
    "    # Reversing the order of the vgg_mean to make it acceptable for PYTHON\n",
    "    return x[:, ::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vgg_Scratch():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224)))\n",
    "    \n",
    "    ConvolutionalLayer(2, model, 64)\n",
    "    ConvolutionalLayer(2, model, 128)\n",
    "    ConvolutionalLayer(3, model, 256)\n",
    "    ConvolutionalLayer(3, model, 512)\n",
    "    ConvolutionalLayer(3, model, 512)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    FullyConnectedLayer(model)\n",
    "    FullyConnectedLayer(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
